{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "099fedac-7c31-4082-91f0-e7b618559d46",
   "metadata": {},
   "source": [
    "## Ungraded Lab: Lambda Layer\n",
    "\n",
    "This lab will show how you can define custom layers with the Lambda layer. You can either use lambda functions within the Lambda layer or define a custom function that the Lambda layer will call. Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4e4238-ddc6-467b-ab78-4ccaffa8c25f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2271eb99-feb1-4977-bfe1-5e8228f10c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "174d4271-e1ec-4a77-8ef6-d9925e5b95d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3db8699-f162-4325-86ee-88449f501df3",
   "metadata": {},
   "source": [
    "## Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32005e1f-8ae2-4aad-85e7-f0ae102e1c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04087d20-d1a4-4d30-a7cd-02e07d9f1a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adutt\\Miniconda3\\envs\\DL\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "train_data = MNIST(root='./', train=True, download=True, transform=transform)\n",
    "test_data = MNIST(root='./', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26a7102b-ccfa-4db1-ac2f-519778b86181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "train_loader = DataLoader(dataset=train_data,\n",
    "                          batch_size=64,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2,\n",
    "                          pin_memory=True)\n",
    "val_loader = DataLoader(dataset=test_data,\n",
    "                        batch_size=64,\n",
    "                        shuffle=True,\n",
    "                        num_workers=2,\n",
    "                        pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ed7f31-4d41-49fb-95f9-4644acf6c5c2",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "739ca43d-d848-4b59-821b-63812c767966",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e602d2cf-196a-4f01-89cc-907a607dd4d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (1): LambdaLayer()\n",
       "  (2): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (3): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the Model\n",
    "modules = []\n",
    "modules.append(nn.Linear(in_features=784, out_features=128))\n",
    "modules.append(LambdaLayer(lambda x: torch.abs(x)))\n",
    "modules.append(nn.Linear(in_features=128, out_features=10))\n",
    "modules.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "model1 = nn.Sequential(*modules)\n",
    "model1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da11e2b6-6ccf-44ff-8f3d-9ad904ed2a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5845fe5e-1581-4e90-8d3e-8dd4a7eb66da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 0.3151100803452578, accuracy: 0.9065166711807251\n",
      "Epoch: 1, loss: 0.14382589405287366, accuracy: 0.9563000202178955\n",
      "Epoch: 2, loss: 0.11083220611852623, accuracy: 0.9659500122070312\n",
      "Epoch: 3, loss: 0.0925293479949784, accuracy: 0.9713500142097473\n",
      "Epoch: 4, loss: 0.07943033080608614, accuracy: 0.9746999740600586\n",
      "\n",
      "Validation - loss: 0.10000009111953294, accuracy: 0.9692000150680542\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "EPOCHS = 5\n",
    "\n",
    "model1.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model1(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(labels.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch: {epoch}, loss: {running_loss/len(train_loader)}, accuracy: {correct/len(train_loader.dataset)}\")\n",
    "\n",
    "\n",
    "# Evaluate Trained Model\n",
    "running_loss = 0\n",
    "correct = 0\n",
    "    \n",
    "model1.eval()\n",
    "for data in val_loader:\n",
    "    images, labels = data\n",
    "    images = images.view(images.shape[0], -1)\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    output = model1(images)\n",
    "    loss = criterion(output, labels)\n",
    "\n",
    "    pred = output.data.max(1, keepdim=True)[1]\n",
    "    correct += pred.eq(labels.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "\n",
    "print(f\"\\nValidation - loss: {running_loss/len(val_loader)}, accuracy: {correct/len(val_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aa4929-20cb-4951-950b-768dd34ee4e2",
   "metadata": {},
   "source": [
    "Another way to use the Lambda layer is to pass in a function defined outside the model. The code below shows how a custom ReLU function is used as a custom layer in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4978c675-0ba7-469c-840c-adf99106fb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9715daa3-bad7-4163-bd8a-5442d2da6edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (1): LambdaLayer()\n",
       "  (2): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (3): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Passing a function to Lambda Layer\n",
    "def my_relu(x):\n",
    "    return torch.maximum(torch.FloatTensor([-0.1]).to(device), x)\n",
    "\n",
    "# Build the Model\n",
    "modules = []\n",
    "modules.append(nn.Linear(in_features=784, out_features=128))\n",
    "modules.append(LambdaLayer(my_relu))\n",
    "modules.append(nn.Linear(in_features=128, out_features=10))\n",
    "modules.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "model2 = nn.Sequential(*modules)\n",
    "model2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dae3d256-cadf-4669-92b3-7f87cb921c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc18d4c0-2a7d-45a4-addd-ba68ebfce026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 0.3820210333421096, accuracy: 0.8890500068664551\n",
      "Epoch: 1, loss: 0.19350487205471947, accuracy: 0.9433833360671997\n",
      "Epoch: 2, loss: 0.1409561559220335, accuracy: 0.9574666619300842\n",
      "Epoch: 3, loss: 0.11247728188146851, accuracy: 0.9668333530426025\n",
      "Epoch: 4, loss: 0.09525075353044611, accuracy: 0.9708166718482971\n",
      "\n",
      "Validation - loss: 0.10198885168298889, accuracy: 0.9692000150680542\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "EPOCHS = 5\n",
    "\n",
    "model2.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model2(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(labels.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch: {epoch}, loss: {running_loss/len(train_loader)}, accuracy: {correct/len(train_loader.dataset)}\")\n",
    "\n",
    "\n",
    "# Evaluate Trained Model\n",
    "running_loss = 0\n",
    "correct = 0\n",
    "    \n",
    "model2.eval()\n",
    "for data in val_loader:\n",
    "    images, labels = data\n",
    "    images = images.view(images.shape[0], -1)\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    output = model2(images)\n",
    "    loss = criterion(output, labels)\n",
    "\n",
    "    pred = output.data.max(1, keepdim=True)[1]\n",
    "    correct += pred.eq(labels.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "\n",
    "print(f\"\\nValidation - loss: {running_loss/len(val_loader)}, accuracy: {correct/len(val_loader.dataset)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e06b8ec-0565-4cb6-bc13-09a12b71355e",
   "metadata": {},
   "source": [
    "## Week 3 Assignment: Implement a Quadratic Layer\n",
    "\n",
    "In this week's programming exercise, you will build a custom quadratic layer which computes y = ax2 + bx + c. Similar to the ungraded lab, this layer will be plugged into a model that will be trained on the MNIST dataset. Let's get started!\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cdd6d6-4cbe-46be-869a-208aa25fd3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d93418f-34d9-4949-8c63-4a2beaf22e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8387cb61-6358-46db-9ba0-2bc8fa7b73d2",
   "metadata": {},
   "source": [
    "## Define the quadratic layer (TODO)\n",
    "\n",
    "Implement a simple quadratic layer. It has 3 state variables: a, b and c. The computation returned is ax^2 + bx +c. Make sure it can also accept an activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a42c9a15-39a2-45c7-879b-6888f5f773c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax**2 + bx + c\n",
    "class SimpleQuadratic(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True, activation=None, device=None, dtype=None):\n",
    "        super(SimpleQuadratic, self).__init__()\n",
    "        \n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        \n",
    "        # Input\n",
    "        self.in_features = in_features\n",
    "        \n",
    "        # Bias\n",
    "        self.bias = bias\n",
    "        \n",
    "        self.apply_activation = False\n",
    "        \n",
    "        # Activation\n",
    "        if activation is not None:\n",
    "            self.apply_activation = True\n",
    "            self.activation = getattr(nn.functional, activation)\n",
    "        \n",
    "        # Weight\n",
    "        self.weight_a = Parameter(torch.empty((out_features, in_features), **factory_kwargs))\n",
    "        self.weight_b = Parameter(torch.empty((out_features, in_features), **factory_kwargs))\n",
    "        self.weight_c = Parameter(torch.zeros((out_features, in_features), **factory_kwargs))\n",
    "        \n",
    "        # Bias\n",
    "        if bias:\n",
    "            self.bias_a = Parameter(torch.empty(out_features, **factory_kwargs))\n",
    "            self.bias_b = Parameter(torch.empty(out_features, **factory_kwargs))\n",
    "            self.bias_c = Parameter(torch.empty(out_features, **factory_kwargs))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        \n",
    "        # Weight and Biase initialization\n",
    "        self._reset_parameters()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x, y = input.shape\n",
    "        if y != self.in_features:\n",
    "            print(f'Wrong Input Features. Please use tensor with {self.in_features} Input Features')\n",
    "            return 0\n",
    "        \n",
    "        # output = input.matmul(self.weight.t())\n",
    "        output = torch.matmul(torch.square(input), self.weight_a.t()) + torch.matmul(input, self.weight_b.t())\n",
    "        \n",
    "        if self.bias is not None:\n",
    "            output += self.bias_a\n",
    "            output += self.bias_b\n",
    "            output += self.bias_c\n",
    "        ret = output\n",
    "        \n",
    "        if self.apply_activation:\n",
    "            return self.activation(ret)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    def _reset_parameters(self):\n",
    "        torch.nn.init.kaiming_uniform_(self.weight_a, a=math.sqrt(5))\n",
    "        torch.nn.init.kaiming_uniform_(self.weight_b, a=math.sqrt(5))\n",
    "        \n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = torch.nn.init._calculate_fan_in_and_fan_out(self.weight_a)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            torch.nn.init.uniform_(self.bias_a, -bound, bound)\n",
    "        \n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = torch.nn.init._calculate_fan_in_and_fan_out(self.weight_b)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            torch.nn.init.uniform_(self.bias_b, -bound, bound)\n",
    "        \n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = torch.nn.init._calculate_fan_in_and_fan_out(self.weight_c)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            torch.nn.init.uniform_(self.bias_c, -bound, bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1f329d-57a7-448c-8c34-173f10e14e8b",
   "metadata": {},
   "source": [
    "## Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1228ca13-7d8f-4b1b-8592-8547385cf6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d63a76c7-909f-4c1a-8f36-70b20fad31ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adutt\\Miniconda3\\envs\\DL\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "train_data = MNIST(root='./', train=True, download=True, transform=transform)\n",
    "test_data = MNIST(root='./', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed2f8f30-e939-4f97-b943-9e004695e1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "train_loader = DataLoader(dataset=train_data,\n",
    "                          batch_size=64,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2,\n",
    "                          pin_memory=True)\n",
    "val_loader = DataLoader(dataset=test_data,\n",
    "                        batch_size=64,\n",
    "                        shuffle=True,\n",
    "                        num_workers=2,\n",
    "                        pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3b5a31-4cc8-4c91-be7f-0a0e3a1c82d4",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "057b1e35-81d0-4565-bdc7-f893f46d6cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): SimpleQuadratic()\n",
       "  (1): Dropout(p=0.2, inplace=False)\n",
       "  (2): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (3): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the Model\n",
    "model = nn.Sequential(\n",
    "    SimpleQuadratic(in_features=784, out_features=128, activation=\"relu\"),\n",
    "    nn.Dropout(0.2),\n",
    "    # SimpleQuadratic(in_features=128, out_features=10),\n",
    "    nn.Linear(in_features=128, out_features=10),\n",
    "    nn.LogSoftmax(dim=1),\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d45c1cf-413e-49e7-92db-54ecc1d3f88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "013f06c0-688c-4ba3-ab68-120ee52d4f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 0.4934732016882917, accuracy: 0.8494166731834412\n",
      "Epoch: 1, loss: 0.2807143531612623, accuracy: 0.9145833253860474\n",
      "Epoch: 2, loss: 0.23896014608585758, accuracy: 0.9272500276565552\n",
      "Epoch: 3, loss: 0.21361781856906947, accuracy: 0.9348499774932861\n",
      "Epoch: 4, loss: 0.19977718043619636, accuracy: 0.9381833076477051\n",
      "\n",
      "Validation - loss: 0.1441410919710709, accuracy: 0.9562000036239624\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "EPOCHS = 5\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(labels.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch: {epoch}, loss: {running_loss/len(train_loader)}, accuracy: {correct/len(train_loader.dataset)}\")\n",
    "\n",
    "\n",
    "# Evaluate Trained Model\n",
    "running_loss = 0\n",
    "correct = 0\n",
    "    \n",
    "model.eval()\n",
    "for data in val_loader:\n",
    "    images, labels = data\n",
    "    images = images.view(images.shape[0], -1)\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    output = model(images)\n",
    "    loss = criterion(output, labels)\n",
    "\n",
    "    pred = output.data.max(1, keepdim=True)[1]\n",
    "    correct += pred.eq(labels.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "\n",
    "print(f\"\\nValidation - loss: {running_loss/len(val_loader)}, accuracy: {correct/len(val_loader.dataset)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98cd83ab-70cd-41c9-8d2f-9a798d821be6",
   "metadata": {},
   "source": [
    "## Ungraded Lab: Activation in Custom Layers\n",
    "\n",
    "In this lab, we extend our knowledge of building custom layers by adding an activation parameter. The implementation is pretty straightforward as you'll see below.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ceacde3-85d3-48be-9eaf-da555213ff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d1c6a55-9225-4324-819d-15012ace56c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8dde33-4cd5-4bb5-830f-94b1a865496d",
   "metadata": {},
   "source": [
    "## Adding an activation layer\n",
    "\n",
    "To use the built-in activations in PyTorch, we can specify an activation parameter in the __init__() method of our custom layer class. From there, we can initialize it by using the forward() method. Then, you can pass in the forward computation to this activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1026ad46-8f6b-443b-b1b7-a3a3d915ab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDense(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True, activation=None, device=None, dtype=None):\n",
    "        super(SimpleDense, self).__init__()\n",
    "        \n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        \n",
    "        # Input\n",
    "        self.in_features = in_features\n",
    "        \n",
    "        # Bias\n",
    "        self.bias = bias\n",
    "        \n",
    "        self.apply_activation = False\n",
    "        \n",
    "        # Activation\n",
    "        if activation is not None:\n",
    "            self.apply_activation = True\n",
    "            self.activation = getattr(nn.functional, activation)\n",
    "        \n",
    "        # Weight\n",
    "        self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))\n",
    "        \n",
    "        # Bias\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.empty(out_features, **factory_kwargs))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        \n",
    "        # Weight and Biase initialization\n",
    "        self._reset_parameters()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x, y = input.shape\n",
    "        if y != self.in_features:\n",
    "            print(f'Wrong Input Features. Please use tensor with {self.in_features} Input Features')\n",
    "            return 0\n",
    "        \n",
    "        output = input.matmul(self.weight.t())\n",
    "        \n",
    "        if self.bias is not None:\n",
    "            output += self.bias\n",
    "        ret = output\n",
    "        \n",
    "        if self.apply_activation:\n",
    "            return self.activation(ret)\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    def _reset_parameters(self):\n",
    "        torch.nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = torch.nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            torch.nn.init.uniform_(self.bias, -bound, bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76cc7cc-a178-499c-82b6-603fc26a3abb",
   "metadata": {},
   "source": [
    "## Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc47bcaa-f2a7-477a-a48b-94763219c740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f364e2a-5b82-4d18-95a3-1b67218a0253",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adutt\\Miniconda3\\envs\\DL\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "train_data = MNIST(root='./', train=True, download=True, transform=transform)\n",
    "test_data = MNIST(root='./', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fa2e5a1-9fee-4cbb-99f8-f3d51248ac01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "train_loader = DataLoader(dataset=train_data,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2,\n",
    "                          pin_memory=True)\n",
    "val_loader = DataLoader(dataset=test_data,\n",
    "                        batch_size=32,\n",
    "                        shuffle=True,\n",
    "                        num_workers=2,\n",
    "                        pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbe5131a-af9c-47f8-b8b6-641cca80b845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): SimpleDense()\n",
       "  (1): Dropout(p=0.2, inplace=False)\n",
       "  (2): SimpleDense()\n",
       "  (3): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the Model\n",
    "model = nn.Sequential(\n",
    "    SimpleDense(in_features=784, out_features=128, activation=\"relu\"),\n",
    "    nn.Dropout(0.2),\n",
    "    SimpleDense(in_features=128, out_features=10),\n",
    "    nn.LogSoftmax(dim=1),\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0987c16e-4720-43d6-8697-c67967ab9cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3b1e1d1-5194-47f7-b537-335a5264bdcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 0.40303231131831807, accuracy: 0.878350019454956\n",
      "Epoch: 1, loss: 0.2336706400046746, accuracy: 0.9296500086784363\n",
      "Epoch: 2, loss: 0.1950585027669867, accuracy: 0.940850019454956\n",
      "Epoch: 3, loss: 0.1770629089380304, accuracy: 0.945816695690155\n",
      "Epoch: 4, loss: 0.16116403914218147, accuracy: 0.9504500031471252\n",
      "\n",
      "Validation - loss: 0.11689013923509434, accuracy: 0.965499997138977\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "EPOCHS = 5\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(labels.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch: {epoch}, loss: {running_loss/len(train_loader)}, accuracy: {correct/len(train_loader.dataset)}\")\n",
    "\n",
    "\n",
    "# Evaluate Trained Model\n",
    "running_loss = 0\n",
    "correct = 0\n",
    "    \n",
    "model.eval()\n",
    "for data in val_loader:\n",
    "    images, labels = data\n",
    "    images = images.view(images.shape[0], -1)\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    output = model(images)\n",
    "    loss = criterion(output, labels)\n",
    "\n",
    "    pred = output.data.max(1, keepdim=True)[1]\n",
    "    correct += pred.eq(labels.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "\n",
    "print(f\"\\nValidation - loss: {running_loss/len(val_loader)}, accuracy: {correct/len(val_loader.dataset)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

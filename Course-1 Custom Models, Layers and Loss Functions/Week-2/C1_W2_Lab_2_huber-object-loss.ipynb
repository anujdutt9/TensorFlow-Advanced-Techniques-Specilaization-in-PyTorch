{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcc8b7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import copy\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e649dc65",
   "metadata": {},
   "source": [
    "## Define a Single Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfec6bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        \n",
    "        self.layer = nn.Linear(in_features=self.in_dim, out_features=self.out_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.layer(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97174835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (layer): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the Model and print it out\n",
    "model = Net(in_dim=1, out_dim=1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "803c1172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two copies of the same model\n",
    "model_huber_wrapper = copy.deepcopy(model)\n",
    "model_huber_class = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a5dd13",
   "metadata": {},
   "source": [
    "## Create the Dataset Class\n",
    "\n",
    "Creating the dataset class is optional to load the dattaset. Instead you can do this as well:\n",
    "\n",
    "```\n",
    "x = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=np.float32)\n",
    "y = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=np.float32)\n",
    "```\n",
    "\n",
    "and then in the training loop, pass the dataset like following:\n",
    "\n",
    "```\n",
    "inputs = Variable(torch.from_numpy(x))\n",
    "labels = Variable(torch.from_numpy(y))\n",
    "```\n",
    "\n",
    "This way you don't need to create the dataloader to load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e7ef335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the artificial dataset\n",
    "class SampleDataset(Dataset):\n",
    "    # Constructor\n",
    "    def __init__(self):\n",
    "        x = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=np.float32)\n",
    "        y = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=np.float32)\n",
    "        self.xs = torch.from_numpy(x)\n",
    "        self.ys = torch.from_numpy(y)\n",
    "    \n",
    "    # Getter\n",
    "    def __getitem__(self, index):\n",
    "        return self.xs[index], self.ys[index]\n",
    "    \n",
    "    # Getting the length\n",
    "    def __len__(self):\n",
    "        return len(self.xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4877e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SampleDataset()\n",
    "trainloader = DataLoader(dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2af4714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model optimizer - SGD\n",
    "optimizer = torch.optim.SGD(model_huber_wrapper.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c03eee",
   "metadata": {},
   "source": [
    "## Custom Loss with Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2cde145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_huber_loss_with_threshold(threshold):\n",
    "    \n",
    "    def huber_loss(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = torch.abs(error) <= threshold\n",
    "        small_error_loss = torch.square(error) / 2\n",
    "        big_error_loss = threshold * (torch.abs(error) - (0.5 * threshold))\n",
    "\n",
    "        return torch.where(is_small_error, small_error_loss, big_error_loss)\n",
    "    \n",
    "    return huber_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de2965c",
   "metadata": {},
   "source": [
    "## Training the Model with Huber Loss Criterion\n",
    "\n",
    "Note that an alternative way of using the Huber loss function could be as follows:\n",
    "\n",
    "```\n",
    "criterion = my_huber_loss_with_threshold(threshold=1.2)\n",
    "loss = criterion(y, output)\n",
    "```\n",
    "\n",
    "instead of using\n",
    "\n",
    "```\n",
    "loss = my_huber_loss_with_threshold(threshold=1.2)(y, output)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e12c0d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|█████▋                                                                 | 40/500 [00:00<00:01, 395.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1.6339493294556935\n",
      "Epoch: 1, Loss: 1.606069785853227\n",
      "Epoch: 2, Loss: 1.5782703844209511\n",
      "Epoch: 3, Loss: 1.5505507563551266\n",
      "Epoch: 4, Loss: 1.5229105614125729\n",
      "Epoch: 5, Loss: 1.4953493848443031\n",
      "Epoch: 6, Loss: 1.4678669460117817\n",
      "Epoch: 7, Loss: 1.4404627978801727\n",
      "Epoch: 8, Loss: 1.4131364561617374\n",
      "Epoch: 9, Loss: 1.3858876166244347\n",
      "Epoch: 10, Loss: 1.3587162494659424\n",
      "Epoch: 11, Loss: 1.3316218592226505\n",
      "Epoch: 12, Loss: 1.3046038908263047\n",
      "Epoch: 13, Loss: 1.2776619084179401\n",
      "Epoch: 14, Loss: 1.2507958561182022\n",
      "Epoch: 15, Loss: 1.2240054694314797\n",
      "Epoch: 16, Loss: 1.1972900989154975\n",
      "Epoch: 17, Loss: 1.1706494676570098\n",
      "Epoch: 18, Loss: 1.144083421677351\n",
      "Epoch: 19, Loss: 1.1175912705560525\n",
      "Epoch: 20, Loss: 1.0911728801826637\n",
      "Epoch: 21, Loss: 1.0648279475669067\n",
      "Epoch: 22, Loss: 1.038577872638901\n",
      "Epoch: 23, Loss: 1.0125776268541813\n",
      "Epoch: 24, Loss: 0.9868877567350864\n",
      "Epoch: 25, Loss: 0.9615036727239689\n",
      "Epoch: 26, Loss: 0.9364211782813072\n",
      "Epoch: 27, Loss: 0.9116363941381375\n",
      "Epoch: 28, Loss: 0.8871451628704866\n",
      "Epoch: 29, Loss: 0.8629426875462135\n",
      "Epoch: 30, Loss: 0.8390256545195977\n",
      "Epoch: 31, Loss: 0.8153898877402147\n",
      "Epoch: 32, Loss: 0.7920314663400253\n",
      "Epoch: 33, Loss: 0.7689465706547102\n",
      "Epoch: 34, Loss: 0.7461313825721542\n",
      "Epoch: 35, Loss: 0.7235820582136512\n",
      "Epoch: 36, Loss: 0.7012949935160577\n",
      "Epoch: 37, Loss: 0.6792665706016123\n",
      "Epoch: 38, Loss: 0.6575105548836291\n",
      "Epoch: 39, Loss: 0.636036962037906\n",
      "Epoch: 40, Loss: 0.6148424275840322\n",
      "Epoch: 41, Loss: 0.593922806593279\n",
      "Epoch: 42, Loss: 0.5732741995792215\n",
      "Epoch: 43, Loss: 0.5528930310004702\n",
      "Epoch: 44, Loss: 0.5327758033721087\n",
      "Epoch: 45, Loss: 0.5129307675330589\n",
      "Epoch: 46, Loss: 0.4935570787832451\n",
      "Epoch: 47, Loss: 0.47480040586015093\n",
      "Epoch: 48, Loss: 0.4566402428346616\n",
      "Epoch: 49, Loss: 0.4390566260617561\n",
      "Epoch: 50, Loss: 0.4220303744053429\n",
      "Epoch: 51, Loss: 0.40554292398155667\n",
      "Epoch: 52, Loss: 0.38957617702544667\n",
      "Epoch: 53, Loss: 0.3741129625899096\n",
      "Epoch: 54, Loss: 0.3591362079217409\n",
      "Epoch: 55, Loss: 0.34463009451671195\n",
      "Epoch: 56, Loss: 0.33057888271287084\n",
      "Epoch: 57, Loss: 0.31696735066361725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|████████████▏                                                          | 86/500 [00:00<00:00, 432.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58, Loss: 0.30378088673266274\n",
      "Epoch: 59, Loss: 0.2910049622878432\n",
      "Epoch: 60, Loss: 0.2786892122433831\n",
      "Epoch: 61, Loss: 0.2670985412163039\n",
      "Epoch: 62, Loss: 0.2562309722416103\n",
      "Epoch: 63, Loss: 0.24603903371219835\n",
      "Epoch: 64, Loss: 0.23647826506445804\n",
      "Epoch: 65, Loss: 0.22750703136747083\n",
      "Epoch: 66, Loss: 0.2190870220462481\n",
      "Epoch: 67, Loss: 0.2111822096630931\n",
      "Epoch: 68, Loss: 0.20375873614102602\n",
      "Epoch: 69, Loss: 0.19678500729302564\n",
      "Epoch: 70, Loss: 0.19023160139719644\n",
      "Epoch: 71, Loss: 0.18407112453132868\n",
      "Epoch: 72, Loss: 0.17827776353806257\n",
      "Epoch: 73, Loss: 0.17282780803119144\n",
      "Epoch: 74, Loss: 0.16769847560984394\n",
      "Epoch: 75, Loss: 0.16286894058187804\n",
      "Epoch: 76, Loss: 0.15831977284202972\n",
      "Epoch: 77, Loss: 0.15403265591400364\n",
      "Epoch: 78, Loss: 0.14999045159978172\n",
      "Epoch: 79, Loss: 0.14617744142500064\n",
      "Epoch: 80, Loss: 0.14257854527871436\n",
      "Epoch: 81, Loss: 0.13917990197660401\n",
      "Epoch: 82, Loss: 0.1359685974312015\n",
      "Epoch: 83, Loss: 0.13293234006656954\n",
      "Epoch: 84, Loss: 0.13005990415695123\n",
      "Epoch: 85, Loss: 0.12734078771366816\n",
      "Epoch: 86, Loss: 0.1247649391007144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██████████████████▌                                                   | 133/500 [00:00<00:00, 447.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87, Loss: 0.1223231937528908\n",
      "Epoch: 88, Loss: 0.12000693654971428\n",
      "Epoch: 89, Loss: 0.11780811978678685\n",
      "Epoch: 90, Loss: 0.11571910746776363\n",
      "Epoch: 91, Loss: 0.11373303469251066\n",
      "Epoch: 92, Loss: 0.11184320019189424\n",
      "Epoch: 93, Loss: 0.11004345633167152\n",
      "Epoch: 94, Loss: 0.10832816187757999\n",
      "Epoch: 95, Loss: 0.10669175534470317\n",
      "Epoch: 96, Loss: 0.1051293717076381\n",
      "Epoch: 97, Loss: 0.10363640706054866\n",
      "Epoch: 98, Loss: 0.1022084485933495\n",
      "Epoch: 99, Loss: 0.10084135374442364\n",
      "Epoch: 100, Loss: 0.09953132298930238\n",
      "Epoch: 101, Loss: 0.0982747848611325\n",
      "Epoch: 102, Loss: 0.09706845103452603\n",
      "Epoch: 103, Loss: 0.09590914899793763\n",
      "Epoch: 104, Loss: 0.09479406557511538\n",
      "Epoch: 105, Loss: 0.09372032918812086\n",
      "Epoch: 106, Loss: 0.09268558824745317\n",
      "Epoch: 107, Loss: 0.09168734436389059\n",
      "Epoch: 108, Loss: 0.09072335832752287\n",
      "Epoch: 109, Loss: 0.08979167913397153\n",
      "Epoch: 110, Loss: 0.08889033280623455\n",
      "Epoch: 111, Loss: 0.08801740741667648\n",
      "Epoch: 112, Loss: 0.08717136216970782\n",
      "Epoch: 113, Loss: 0.08635056220615904\n",
      "Epoch: 114, Loss: 0.08555352680074672\n",
      "Epoch: 115, Loss: 0.08477875605846445\n",
      "Epoch: 116, Loss: 0.08402508691263695\n",
      "Epoch: 117, Loss: 0.08329133014194667\n",
      "Epoch: 118, Loss: 0.08257626905106008\n",
      "Epoch: 119, Loss: 0.08187887394645561\n",
      "Epoch: 120, Loss: 0.0811982088489458\n",
      "Epoch: 121, Loss: 0.08053330495022237\n",
      "Epoch: 122, Loss: 0.07988332704796146\n",
      "Epoch: 123, Loss: 0.07924745002916704\n",
      "Epoch: 124, Loss: 0.07862491928972304\n",
      "Epoch: 125, Loss: 0.0780150763457641\n",
      "Epoch: 126, Loss: 0.07741717679891735\n",
      "Epoch: 127, Loss: 0.07683066470781341\n",
      "Epoch: 128, Loss: 0.07625493440233792\n",
      "Epoch: 129, Loss: 0.07568945918076982\n",
      "Epoch: 130, Loss: 0.07513376102239515\n",
      "Epoch: 131, Loss: 0.0745872919796966\n",
      "Epoch: 132, Loss: 0.07404966646572575\n",
      "Epoch: 133, Loss: 0.07352044113213196\n",
      "Epoch: 134, Loss: 0.07299923592169459\n",
      "Epoch: 135, Loss: 0.07248567776211227\n",
      "Epoch: 136, Loss: 0.07197944641423722\n",
      "Epoch: 137, Loss: 0.07148017392804225\n",
      "Epoch: 138, Loss: 0.07098767500914012\n",
      "Epoch: 139, Loss: 0.07050152728334069\n",
      "Epoch: 140, Loss: 0.070021565722224\n",
      "Epoch: 141, Loss: 0.06954751725425012\n",
      "Epoch: 142, Loss: 0.06907914124894887\n",
      "Epoch: 143, Loss: 0.06861621115240268\n",
      "Epoch: 144, Loss: 0.06815853441366926\n",
      "Epoch: 145, Loss: 0.06770590441010427\n",
      "Epoch: 146, Loss: 0.06725820322268798\n",
      "Epoch: 147, Loss: 0.06681523437146097\n",
      "Epoch: 148, Loss: 0.06637672805906429\n",
      "Epoch: 149, Loss: 0.06594268346331471\n",
      "Epoch: 150, Loss: 0.06551290970674017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|████████████████████████▉                                             | 178/500 [00:00<00:00, 437.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 151, Loss: 0.06508725533058168\n",
      "Epoch: 152, Loss: 0.06466561988781905\n",
      "Epoch: 153, Loss: 0.06424788427830208\n",
      "Epoch: 154, Loss: 0.06383398035541177\n",
      "Epoch: 155, Loss: 0.0634236922681642\n",
      "Epoch: 156, Loss: 0.06301704718498513\n",
      "Epoch: 157, Loss: 0.06261383917808416\n",
      "Epoch: 158, Loss: 0.062214070899547856\n",
      "Epoch: 159, Loss: 0.061817633376146354\n",
      "Epoch: 160, Loss: 0.06142441100018914\n",
      "Epoch: 161, Loss: 0.06103434161195764\n",
      "Epoch: 162, Loss: 0.060647434397348356\n",
      "Epoch: 163, Loss: 0.06026355733774835\n",
      "Epoch: 164, Loss: 0.059882649235078134\n",
      "Epoch: 165, Loss: 0.05950462954933755\n",
      "Epoch: 166, Loss: 0.059129484657811794\n",
      "Epoch: 167, Loss: 0.058757184254621585\n",
      "Epoch: 168, Loss: 0.05838761156307252\n",
      "Epoch: 169, Loss: 0.058020747756017954\n",
      "Epoch: 170, Loss: 0.05765659398972881\n",
      "Epoch: 171, Loss: 0.05729499899174092\n",
      "Epoch: 172, Loss: 0.05693605589840445\n",
      "Epoch: 173, Loss: 0.05657963687379682\n",
      "Epoch: 174, Loss: 0.05622574258042808\n",
      "Epoch: 175, Loss: 0.05587429340933644\n",
      "Epoch: 176, Loss: 0.05552527271510144\n",
      "Epoch: 177, Loss: 0.05517866820961596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|███████████████████████████████▋                                      | 226/500 [00:00<00:00, 451.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 178, Loss: 0.054834419600126694\n",
      "Epoch: 179, Loss: 0.054492509034105296\n",
      "Epoch: 180, Loss: 0.05415293483141189\n",
      "Epoch: 181, Loss: 0.05381564702264541\n",
      "Epoch: 182, Loss: 0.05348061038830565\n",
      "Epoch: 183, Loss: 0.05314778867402007\n",
      "Epoch: 184, Loss: 0.0528172055989368\n",
      "Epoch: 185, Loss: 0.052488804908231636\n",
      "Epoch: 186, Loss: 0.05216253597010715\n",
      "Epoch: 187, Loss: 0.05183840818919331\n",
      "Epoch: 188, Loss: 0.05151641463574682\n",
      "Epoch: 189, Loss: 0.05119649516791469\n",
      "Epoch: 190, Loss: 0.0508786788004727\n",
      "Epoch: 191, Loss: 0.050562921344256516\n",
      "Epoch: 192, Loss: 0.05024919825094306\n",
      "Epoch: 193, Loss: 0.04993748352596109\n",
      "Epoch: 194, Loss: 0.04962778550422323\n",
      "Epoch: 195, Loss: 0.0493200520722894\n",
      "Epoch: 196, Loss: 0.049014302901923656\n",
      "Epoch: 197, Loss: 0.04871050133685154\n",
      "Epoch: 198, Loss: 0.048408633953537596\n",
      "Epoch: 199, Loss: 0.0481086822492216\n",
      "Epoch: 200, Loss: 0.04781062937430155\n",
      "Epoch: 201, Loss: 0.0475144792132293\n",
      "Epoch: 202, Loss: 0.04722021530263495\n",
      "Epoch: 203, Loss: 0.046927788918765145\n",
      "Epoch: 204, Loss: 0.04663721240891997\n",
      "Epoch: 205, Loss: 0.04634847547549725\n",
      "Epoch: 206, Loss: 0.04606156541619081\n",
      "Epoch: 207, Loss: 0.045776443482585215\n",
      "Epoch: 208, Loss: 0.04549310568957784\n",
      "Epoch: 209, Loss: 0.04521153593001751\n",
      "Epoch: 210, Loss: 0.04493174160294681\n",
      "Epoch: 211, Loss: 0.04465367234600611\n",
      "Epoch: 212, Loss: 0.04437740197560439\n",
      "Epoch: 213, Loss: 0.04410282424578327\n",
      "Epoch: 214, Loss: 0.04382992127527056\n",
      "Epoch: 215, Loss: 0.043558775363635505\n",
      "Epoch: 216, Loss: 0.04328929885984204\n",
      "Epoch: 217, Loss: 0.0430215321060435\n",
      "Epoch: 218, Loss: 0.042755430133183836\n",
      "Epoch: 219, Loss: 0.04249096590986786\n",
      "Epoch: 220, Loss: 0.04222814002241648\n",
      "Epoch: 221, Loss: 0.04196696884173434\n",
      "Epoch: 222, Loss: 0.04170738921190301\n",
      "Epoch: 223, Loss: 0.041449463213818184\n",
      "Epoch: 224, Loss: 0.04119314929569858\n",
      "Epoch: 225, Loss: 0.040938399649652034\n",
      "Epoch: 226, Loss: 0.040685213563847356\n",
      "Epoch: 227, Loss: 0.04043362179921436\n",
      "Epoch: 228, Loss: 0.04018361754181873\n",
      "Epoch: 229, Loss: 0.039935142020112835\n",
      "Epoch: 230, Loss: 0.039688201548415236\n",
      "Epoch: 231, Loss: 0.039442818570629846\n",
      "Epoch: 232, Loss: 0.03919894599918431\n",
      "Epoch: 233, Loss: 0.03895656120403146\n",
      "Epoch: 234, Loss: 0.03871568820795801\n",
      "Epoch: 235, Loss: 0.03847631819977929\n",
      "Epoch: 236, Loss: 0.038238424288768634\n",
      "Epoch: 237, Loss: 0.03800201857484353\n",
      "Epoch: 238, Loss: 0.037767056535813026\n",
      "Epoch: 239, Loss: 0.037533557449326814\n",
      "Epoch: 240, Loss: 0.03730149918313449\n",
      "Epoch: 241, Loss: 0.03707088969834634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|██████████████████████████████████████                                | 272/500 [00:00<00:00, 450.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 242, Loss: 0.03684170590592354\n",
      "Epoch: 243, Loss: 0.036613929090284124\n",
      "Epoch: 244, Loss: 0.03638758249750632\n",
      "Epoch: 245, Loss: 0.03616261856526156\n",
      "Epoch: 246, Loss: 0.035939058366542063\n",
      "Epoch: 247, Loss: 0.03571688313725948\n",
      "Epoch: 248, Loss: 0.035496082965134214\n",
      "Epoch: 249, Loss: 0.035276651966948215\n",
      "Epoch: 250, Loss: 0.03505855878271783\n",
      "Epoch: 251, Loss: 0.034841821995845144\n",
      "Epoch: 252, Loss: 0.03462643302797611\n",
      "Epoch: 253, Loss: 0.03441235176372478\n",
      "Epoch: 254, Loss: 0.03419958877566387\n",
      "Epoch: 255, Loss: 0.033988165620030486\n",
      "Epoch: 256, Loss: 0.033778048602471245\n",
      "Epoch: 257, Loss: 0.033569222989778304\n",
      "Epoch: 258, Loss: 0.03336168217477583\n",
      "Epoch: 259, Loss: 0.033155457786051556\n",
      "Epoch: 260, Loss: 0.032950502939153616\n",
      "Epoch: 261, Loss: 0.03274680917881293\n",
      "Epoch: 262, Loss: 0.03254438166428978\n",
      "Epoch: 263, Loss: 0.03234319425852542\n",
      "Epoch: 264, Loss: 0.03214325274105553\n",
      "Epoch: 265, Loss: 0.03194454301168056\n",
      "Epoch: 266, Loss: 0.03174706714404844\n",
      "Epoch: 267, Loss: 0.03155081862314546\n",
      "Epoch: 268, Loss: 0.03135578066091208\n",
      "Epoch: 269, Loss: 0.03116197186560991\n",
      "Epoch: 270, Loss: 0.030969313587168774\n",
      "Epoch: 271, Loss: 0.03077786901788689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|████████████████████████████████████████████▊                         | 320/500 [00:00<00:00, 457.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 272, Loss: 0.030587624254621915\n",
      "Epoch: 273, Loss: 0.030398530444169108\n",
      "Epoch: 274, Loss: 0.030210602528920088\n",
      "Epoch: 275, Loss: 0.03002387479621878\n",
      "Epoch: 276, Loss: 0.029838281188858673\n",
      "Epoch: 277, Loss: 0.029653837094277453\n",
      "Epoch: 278, Loss: 0.029470506583796425\n",
      "Epoch: 279, Loss: 0.029288326136641746\n",
      "Epoch: 280, Loss: 0.02910728342673489\n",
      "Epoch: 281, Loss: 0.028927362451213412\n",
      "Epoch: 282, Loss: 0.02874854080134052\n",
      "Epoch: 283, Loss: 0.028570832442104194\n",
      "Epoch: 284, Loss: 0.02839423163883718\n",
      "Epoch: 285, Loss: 0.02821867459291146\n",
      "Epoch: 286, Loss: 0.028044239619096818\n",
      "Epoch: 287, Loss: 0.027870860050218955\n",
      "Epoch: 288, Loss: 0.027698559488271712\n",
      "Epoch: 289, Loss: 0.027527327369777293\n",
      "Epoch: 290, Loss: 0.027357164025791764\n",
      "Epoch: 291, Loss: 0.02718805973866741\n",
      "Epoch: 292, Loss: 0.02702001172898842\n",
      "Epoch: 293, Loss: 0.026852966992616228\n",
      "Epoch: 294, Loss: 0.02668697867314525\n",
      "Epoch: 295, Loss: 0.02652201818515702\n",
      "Epoch: 296, Loss: 0.026358064136123478\n",
      "Epoch: 297, Loss: 0.02619513941317564\n",
      "Epoch: 298, Loss: 0.026033185502456035\n",
      "Epoch: 299, Loss: 0.025872264569746523\n",
      "Epoch: 300, Loss: 0.025712332241406937\n",
      "Epoch: 301, Loss: 0.02555338821972934\n",
      "Epoch: 302, Loss: 0.025395409123423935\n",
      "Epoch: 303, Loss: 0.02523842886694183\n",
      "Epoch: 304, Loss: 0.025082424785068724\n",
      "Epoch: 305, Loss: 0.024927366013192415\n",
      "Epoch: 306, Loss: 0.024773277894685936\n",
      "Epoch: 307, Loss: 0.024620145947361987\n",
      "Epoch: 308, Loss: 0.02446794568459154\n",
      "Epoch: 309, Loss: 0.02431669150731371\n",
      "Epoch: 310, Loss: 0.024166365798616123\n",
      "Epoch: 311, Loss: 0.0240169742131305\n",
      "Epoch: 312, Loss: 0.02386849566513168\n",
      "Epoch: 313, Loss: 0.023720944445206744\n",
      "Epoch: 314, Loss: 0.02357430495855321\n",
      "Epoch: 315, Loss: 0.02342857516608395\n",
      "Epoch: 316, Loss: 0.023283759539481252\n",
      "Epoch: 317, Loss: 0.023139816302621814\n",
      "Epoch: 318, Loss: 0.02299679265646167\n",
      "Epoch: 319, Loss: 0.02285462018092706\n",
      "Epoch: 320, Loss: 0.022713346961002873\n",
      "Epoch: 321, Loss: 0.0225729584981309\n",
      "Epoch: 322, Loss: 0.02243341137727839\n",
      "Epoch: 323, Loss: 0.02229473565967055\n",
      "Epoch: 324, Loss: 0.02215694032687073\n",
      "Epoch: 325, Loss: 0.022019955818905146\n",
      "Epoch: 326, Loss: 0.02188383528906949\n",
      "Epoch: 327, Loss: 0.021748558788506973\n",
      "Epoch: 328, Loss: 0.021614114642943605\n",
      "Epoch: 329, Loss: 0.02148050242734219\n",
      "Epoch: 330, Loss: 0.021347709648277185\n",
      "Epoch: 331, Loss: 0.021215740491849527\n",
      "Epoch: 332, Loss: 0.021084603994192246\n",
      "Epoch: 333, Loss: 0.02095425408576072\n",
      "Epoch: 334, Loss: 0.020824724256575184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████████████████████████████████████████████████▊                  | 370/500 [00:00<00:00, 470.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 335, Loss: 0.020695987666840665\n",
      "Epoch: 336, Loss: 0.020568038132599515\n",
      "Epoch: 337, Loss: 0.02044089242796569\n",
      "Epoch: 338, Loss: 0.020314528007171855\n",
      "Epoch: 339, Loss: 0.02018896247439746\n",
      "Epoch: 340, Loss: 0.02006416606066826\n",
      "Epoch: 341, Loss: 0.019940135589422425\n",
      "Epoch: 342, Loss: 0.019816869355660554\n",
      "Epoch: 343, Loss: 0.019694370257639093\n",
      "Epoch: 344, Loss: 0.019572619005581753\n",
      "Epoch: 345, Loss: 0.019451626064740896\n",
      "Epoch: 346, Loss: 0.01933138169988524\n",
      "Epoch: 347, Loss: 0.01921187448897399\n",
      "Epoch: 348, Loss: 0.01909311511735723\n",
      "Epoch: 349, Loss: 0.018975067800662753\n",
      "Epoch: 350, Loss: 0.01885776781394573\n",
      "Epoch: 351, Loss: 0.018741175459581427\n",
      "Epoch: 352, Loss: 0.01862533894806499\n",
      "Epoch: 353, Loss: 0.018510179867007537\n",
      "Epoch: 354, Loss: 0.01839575925684282\n",
      "Epoch: 355, Loss: 0.018282024466316216\n",
      "Epoch: 356, Loss: 0.01816903334596039\n",
      "Epoch: 357, Loss: 0.01805671012940972\n",
      "Epoch: 358, Loss: 0.017945077971186645\n",
      "Epoch: 359, Loss: 0.01783414834062569\n",
      "Epoch: 360, Loss: 0.017723897137329914\n",
      "Epoch: 361, Loss: 0.017614332578887115\n",
      "Epoch: 362, Loss: 0.01750544903431243\n",
      "Epoch: 363, Loss: 0.017397246483596973\n",
      "Epoch: 364, Loss: 0.017289698281577632\n",
      "Epoch: 365, Loss: 0.01718282340395187\n",
      "Epoch: 366, Loss: 0.017076610597844894\n",
      "Epoch: 367, Loss: 0.01697104088695293\n",
      "Epoch: 368, Loss: 0.016866140970402437\n",
      "Epoch: 369, Loss: 0.01676186745862651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|██████████████████████████████████████████████████████████▌           | 418/500 [00:00<00:00, 459.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 370, Loss: 0.016658250662355083\n",
      "Epoch: 371, Loss: 0.016555276098188187\n",
      "Epoch: 372, Loss: 0.01645294101975499\n",
      "Epoch: 373, Loss: 0.01635123473048831\n",
      "Epoch: 374, Loss: 0.016250155842499225\n",
      "Epoch: 375, Loss: 0.016149697682218783\n",
      "Epoch: 376, Loss: 0.01604986240636208\n",
      "Epoch: 377, Loss: 0.015950649562000763\n",
      "Epoch: 378, Loss: 0.015852046352241207\n",
      "Epoch: 379, Loss: 0.015754052554560378\n",
      "Epoch: 380, Loss: 0.015656668218374154\n",
      "Epoch: 381, Loss: 0.015559868067612115\n",
      "Epoch: 382, Loss: 0.015463678115641718\n",
      "Epoch: 383, Loss: 0.015368087312405502\n",
      "Epoch: 384, Loss: 0.015273097323188267\n",
      "Epoch: 385, Loss: 0.015178666280614076\n",
      "Epoch: 386, Loss: 0.015084842974526206\n",
      "Epoch: 387, Loss: 0.014991580533205706\n",
      "Epoch: 388, Loss: 0.014898922525996264\n",
      "Epoch: 389, Loss: 0.014806807835460253\n",
      "Epoch: 390, Loss: 0.014715276624580534\n",
      "Epoch: 391, Loss: 0.014624322024853123\n",
      "Epoch: 392, Loss: 0.014533933213897399\n",
      "Epoch: 393, Loss: 0.014444090394439021\n",
      "Epoch: 394, Loss: 0.014354805668517656\n",
      "Epoch: 395, Loss: 0.014266046298265186\n",
      "Epoch: 396, Loss: 0.014177871665500183\n",
      "Epoch: 397, Loss: 0.014090225040187457\n",
      "Epoch: 398, Loss: 0.014003110812457939\n",
      "Epoch: 399, Loss: 0.013916550668606456\n",
      "Epoch: 400, Loss: 0.013830525237911692\n",
      "Epoch: 401, Loss: 0.013745036561886081\n",
      "Epoch: 402, Loss: 0.013660052954340548\n",
      "Epoch: 403, Loss: 0.01357561508514967\n",
      "Epoch: 404, Loss: 0.013491688373202729\n",
      "Epoch: 405, Loss: 0.013408291338237177\n",
      "Epoch: 406, Loss: 0.013325403545119721\n",
      "Epoch: 407, Loss: 0.01324303219007561\n",
      "Epoch: 408, Loss: 0.013161167068574287\n",
      "Epoch: 409, Loss: 0.013079807992653514\n",
      "Epoch: 410, Loss: 0.012998948415164099\n",
      "Epoch: 411, Loss: 0.012918602715217276\n",
      "Epoch: 412, Loss: 0.012838744403173527\n",
      "Epoch: 413, Loss: 0.012759376932687397\n",
      "Epoch: 414, Loss: 0.012680509500569315\n",
      "Epoch: 415, Loss: 0.012602122684863085\n",
      "Epoch: 416, Loss: 0.012524208194311845\n",
      "Epoch: 417, Loss: 0.012446789392318655\n",
      "Epoch: 418, Loss: 0.012369851368627375\n",
      "Epoch: 419, Loss: 0.012293380030314438\n",
      "Epoch: 420, Loss: 0.012217394534066747\n",
      "Epoch: 421, Loss: 0.012141860624372688\n",
      "Epoch: 422, Loss: 0.01206681279957896\n",
      "Epoch: 423, Loss: 0.011992208530500648\n",
      "Epoch: 424, Loss: 0.011918084424905828\n",
      "Epoch: 425, Loss: 0.011844390037974032\n",
      "Epoch: 426, Loss: 0.011771174689177618\n",
      "Epoch: 427, Loss: 0.011698407470551805\n",
      "Epoch: 428, Loss: 0.011626086098961727\n",
      "Epoch: 429, Loss: 0.011554218498531554\n",
      "Epoch: 430, Loss: 0.011482796360117694\n",
      "Epoch: 431, Loss: 0.011411790384651491\n",
      "Epoch: 432, Loss: 0.011341251863996149\n",
      "Epoch: 433, Loss: 0.011271142420203736\n",
      "Epoch: 434, Loss: 0.011201456083654193\n",
      "Epoch: 435, Loss: 0.011132208418227188\n",
      "Epoch: 436, Loss: 0.011063381952529502\n",
      "Epoch: 437, Loss: 0.010994986906553095\n",
      "Epoch: 438, Loss: 0.010927012260860161\n",
      "Epoch: 439, Loss: 0.010859470399130563\n",
      "Epoch: 440, Loss: 0.010792341595030544\n",
      "Epoch: 441, Loss: 0.010725629175491727\n",
      "Epoch: 442, Loss: 0.010659323136981888\n",
      "Epoch: 443, Loss: 0.010593434767846096\n",
      "Epoch: 444, Loss: 0.010527946908647815\n",
      "Epoch: 445, Loss: 0.010462860141463656\n",
      "Epoch: 446, Loss: 0.010398179064698828\n",
      "Epoch: 447, Loss: 0.010333912234879486\n",
      "Epoch: 448, Loss: 0.01027001782131265\n",
      "Epoch: 449, Loss: 0.010206538369857299\n",
      "Epoch: 450, Loss: 0.010143444583566938\n",
      "Epoch: 451, Loss: 0.010080744768856675\n",
      "Epoch: 452, Loss: 0.01001842885549801\n",
      "Epoch: 453, Loss: 0.009956502114922236\n",
      "Epoch: 454, Loss: 0.00989494839541294\n",
      "Epoch: 455, Loss: 0.009833773600803397\n",
      "Epoch: 456, Loss: 0.009772987622151655\n",
      "Epoch: 457, Loss: 0.009712583804988148\n",
      "Epoch: 458, Loss: 0.009652535408955979\n",
      "Epoch: 459, Loss: 0.009592863177507146\n",
      "Epoch: 460, Loss: 0.00953356945926013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 454.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 461, Loss: 0.009474641708341855\n",
      "Epoch: 462, Loss: 0.00941606075502932\n",
      "Epoch: 463, Loss: 0.009357853918421219\n",
      "Epoch: 464, Loss: 0.009299997646545913\n",
      "Epoch: 465, Loss: 0.0092425212718202\n",
      "Epoch: 466, Loss: 0.009185383151816495\n",
      "Epoch: 467, Loss: 0.009128594834085865\n",
      "Epoch: 468, Loss: 0.009072168027159933\n",
      "Epoch: 469, Loss: 0.009016087105919723\n",
      "Epoch: 470, Loss: 0.008960353747170302\n",
      "Epoch: 471, Loss: 0.008904965281847884\n",
      "Epoch: 472, Loss: 0.008849925371881303\n",
      "Epoch: 473, Loss: 0.008795217614533613\n",
      "Epoch: 474, Loss: 0.008740841464411156\n",
      "Epoch: 475, Loss: 0.008686803040897454\n",
      "Epoch: 476, Loss: 0.00863310679415008\n",
      "Epoch: 477, Loss: 0.008579743505227574\n",
      "Epoch: 478, Loss: 0.008526703689919183\n",
      "Epoch: 479, Loss: 0.008473991529475219\n",
      "Epoch: 480, Loss: 0.008421597842546666\n",
      "Epoch: 481, Loss: 0.008369539119788291\n",
      "Epoch: 482, Loss: 0.00831780754894377\n",
      "Epoch: 483, Loss: 0.00826638388025458\n",
      "Epoch: 484, Loss: 0.008215287124130555\n",
      "Epoch: 485, Loss: 0.008164494018880456\n",
      "Epoch: 486, Loss: 0.008114010361168766\n",
      "Epoch: 487, Loss: 0.008063860939576747\n",
      "Epoch: 488, Loss: 0.008014011081589464\n",
      "Epoch: 489, Loss: 0.007964466607973009\n",
      "Epoch: 490, Loss: 0.007915240052777031\n",
      "Epoch: 491, Loss: 0.007866311898396816\n",
      "Epoch: 492, Loss: 0.0078176901374718\n",
      "Epoch: 493, Loss: 0.0077693640362970955\n",
      "Epoch: 494, Loss: 0.007721328944777876\n",
      "Epoch: 495, Loss: 0.007673604308214029\n",
      "Epoch: 496, Loss: 0.007626164596634529\n",
      "Epoch: 497, Loss: 0.007579024012860221\n",
      "Epoch: 498, Loss: 0.007532172735106239\n",
      "Epoch: 499, Loss: 0.007485610569498628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 500\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    running_loss = 0\n",
    "    for idx, (x, y) in enumerate(trainloader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model_huber_wrapper(x)\n",
    "        loss = my_huber_loss_with_threshold(threshold=1.2)(y, output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch: {epoch}, Loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc71009",
   "metadata": {},
   "source": [
    "## Inference using Huber Loss Wrapper Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8d3e09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18.6420], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sample = [10.0]\n",
    "\n",
    "# Set model to Eval mode\n",
    "model_huber_wrapper.eval()\n",
    "output = model_huber_wrapper(torch.tensor(sample))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bb819a",
   "metadata": {},
   "source": [
    "## Define Custom Loss Function\n",
    "\n",
    "Here, we define the Huber Loss function that takes in two parameters:\n",
    "\n",
    "```\n",
    "y_true: the actual label\n",
    "y_pred: the predicted output by the model\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e965aac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberLoss(nn.Module):\n",
    "    def __init__(self, threshold):\n",
    "        super(HuberLoss, self).__init__()\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def forward(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = torch.abs(error) <= self.threshold\n",
    "        small_error_loss = torch.square(error) / 2\n",
    "        big_error_loss = self.threshold * (torch.abs(error) - (0.5 * self.threshold))\n",
    "        \n",
    "        return torch.where(is_small_error, small_error_loss, big_error_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ff48dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model optimizer - SGD\n",
    "optimizer = torch.optim.SGD(model_huber_class.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f71c4f",
   "metadata": {},
   "source": [
    "## Train the Model with Huber Loss Function\n",
    "\n",
    "Note that an alternative way of using the Huber loss function could be as follows:\n",
    "\n",
    "```\n",
    "criterion = HuberLoss(threshold=1.2)\n",
    "loss = criterion(y, output)\n",
    "```\n",
    "\n",
    "instead of using\n",
    "\n",
    "```\n",
    "loss = HuberLoss(threshold=1.02)(y, output)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ab13c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                 | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1.4593588970601559\n",
      "Epoch: 1, Loss: 1.4388243469099204\n",
      "Epoch: 2, Loss: 1.4183488003909588\n",
      "Epoch: 3, Loss: 1.39793220286568\n",
      "Epoch: 4, Loss: 1.377574160695076\n",
      "Epoch: 5, Loss: 1.3572744131088257\n",
      "Epoch: 6, Loss: 1.3370326136549313\n",
      "Epoch: 7, Loss: 1.3168485711018245\n",
      "Epoch: 8, Loss: 1.2967220780750115\n",
      "Epoch: 9, Loss: 1.276652862628301\n",
      "Epoch: 10, Loss: 1.2566406304637592\n",
      "Epoch: 11, Loss: 1.236685066173474\n",
      "Epoch: 12, Loss: 1.2167858531077702\n",
      "Epoch: 13, Loss: 1.196943011134863\n",
      "Epoch: 14, Loss: 1.1771560894946258\n",
      "Epoch: 15, Loss: 1.157424954076608\n",
      "Epoch: 16, Loss: 1.137749249736468\n",
      "Epoch: 17, Loss: 1.1181286126375198\n",
      "Epoch: 18, Loss: 1.0985628354052703\n",
      "Epoch: 19, Loss: 1.0790517355004947\n",
      "Epoch: 20, Loss: 1.0595950732628505\n",
      "Epoch: 21, Loss: 1.0401926959554355\n",
      "Epoch: 22, Loss: 1.0208442422250907\n",
      "Epoch: 23, Loss: 1.0015493494768937\n",
      "Epoch: 24, Loss: 0.9823079208532969\n",
      "Epoch: 25, Loss: 0.9631197775403658\n",
      "Epoch: 26, Loss: 0.9439844905088345\n",
      "Epoch: 27, Loss: 0.9249021125336488\n",
      "Epoch: 28, Loss: 0.905872222657005\n",
      "Epoch: 29, Loss: 0.8868945247183243\n",
      "Epoch: 30, Loss: 0.8679687318702539\n",
      "Epoch: 31, Loss: 0.8490946609526873\n",
      "Epoch: 32, Loss: 0.8302723187953234\n",
      "Epoch: 33, Loss: 0.8115009938677152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|█████▌                                                                 | 39/500 [00:00<00:01, 382.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34, Loss: 0.7928392638762792\n",
      "Epoch: 35, Loss: 0.7743846823771795\n",
      "Epoch: 36, Loss: 0.7561482808863124\n",
      "Epoch: 37, Loss: 0.7381265467653672\n",
      "Epoch: 38, Loss: 0.7203166745603085\n",
      "Epoch: 39, Loss: 0.7027159774055084\n",
      "Epoch: 40, Loss: 0.6853211068858703\n",
      "Epoch: 41, Loss: 0.6681293387276431\n",
      "Epoch: 42, Loss: 0.6511379952232043\n",
      "Epoch: 43, Loss: 0.6343440939672291\n",
      "Epoch: 44, Loss: 0.6177450804971159\n",
      "Epoch: 45, Loss: 0.6013381453230977\n",
      "Epoch: 46, Loss: 0.5851207891634355\n",
      "Epoch: 47, Loss: 0.5690901086976131\n",
      "Epoch: 48, Loss: 0.5532437614165246\n",
      "Epoch: 49, Loss: 0.5375790335626031\n",
      "Epoch: 50, Loss: 0.5220934509610137\n",
      "Epoch: 51, Loss: 0.5067846482464423\n",
      "Epoch: 52, Loss: 0.491649835263767\n",
      "Epoch: 53, Loss: 0.47668695011816453\n",
      "Epoch: 54, Loss: 0.46189354769982555\n",
      "Epoch: 55, Loss: 0.44726707096318324\n",
      "Epoch: 56, Loss: 0.43280550051808103\n",
      "Epoch: 57, Loss: 0.41850618311097304\n",
      "Epoch: 58, Loss: 0.4043672705253509\n",
      "Epoch: 59, Loss: 0.39048017729267787\n",
      "Epoch: 60, Loss: 0.37699284737270017\n",
      "Epoch: 61, Loss: 0.3639079876593314\n",
      "Epoch: 62, Loss: 0.35121197587189573\n",
      "Epoch: 63, Loss: 0.3388923593641569\n",
      "Epoch: 64, Loss: 0.3269364605269705\n",
      "Epoch: 65, Loss: 0.3153331369006385\n",
      "Epoch: 66, Loss: 0.30408304603770375\n",
      "Epoch: 67, Loss: 0.2931811062153429\n",
      "Epoch: 68, Loss: 0.28261566410462063\n",
      "Epoch: 69, Loss: 0.27237549307756126\n",
      "Epoch: 70, Loss: 0.2624496979018052\n",
      "Epoch: 71, Loss: 0.25282800088947016\n",
      "Epoch: 72, Loss: 0.24350042967125773\n",
      "Epoch: 73, Loss: 0.23445698603366813\n",
      "Epoch: 74, Loss: 0.2256967119562129\n",
      "Epoch: 75, Loss: 0.2173555538368722\n",
      "Epoch: 76, Loss: 0.2095244120185574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|███████████                                                            | 78/500 [00:00<00:01, 378.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77, Loss: 0.20216993180414042\n",
      "Epoch: 78, Loss: 0.19526090690245232\n",
      "Epoch: 79, Loss: 0.18876813383152088\n",
      "Epoch: 80, Loss: 0.1826646247257789\n",
      "Epoch: 81, Loss: 0.17692468858634433\n",
      "Epoch: 82, Loss: 0.17152475782980522\n",
      "Epoch: 83, Loss: 0.16644246371773383\n",
      "Epoch: 84, Loss: 0.1616572089648495\n",
      "Epoch: 85, Loss: 0.15714963044350347\n",
      "Epoch: 86, Loss: 0.15290150376191983\n",
      "Epoch: 87, Loss: 0.1488960743881762\n",
      "Epoch: 88, Loss: 0.14511748523606607\n",
      "Epoch: 89, Loss: 0.14155109217002368\n",
      "Epoch: 90, Loss: 0.13818301217785725\n",
      "Epoch: 91, Loss: 0.1350004786994153\n",
      "Epoch: 92, Loss: 0.13199131345997253\n",
      "Epoch: 93, Loss: 0.12914450857594298\n",
      "Epoch: 94, Loss: 0.1264494480759216\n",
      "Epoch: 95, Loss: 0.1238963327887177\n",
      "Epoch: 96, Loss: 0.12147603192139893\n",
      "Epoch: 97, Loss: 0.11918001494946869\n",
      "Epoch: 98, Loss: 0.11700028055080718\n",
      "Epoch: 99, Loss: 0.11492931347553774\n",
      "Epoch: 100, Loss: 0.11296021637341862\n",
      "Epoch: 101, Loss: 0.11108649850454337\n",
      "Epoch: 102, Loss: 0.10930207209700409\n",
      "Epoch: 103, Loss: 0.10760127332954046\n",
      "Epoch: 104, Loss: 0.10597873422860478\n",
      "Epoch: 105, Loss: 0.10442947454672928\n",
      "Epoch: 106, Loss: 0.10294895176775753\n",
      "Epoch: 107, Loss: 0.10153280780650675\n",
      "Epoch: 108, Loss: 0.10017689730739221\n",
      "Epoch: 109, Loss: 0.09887756094879781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|████████████████▏                                                     | 116/500 [00:00<00:01, 377.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 110, Loss: 0.09763122590569158\n",
      "Epoch: 111, Loss: 0.0964345761652415\n",
      "Epoch: 112, Loss: 0.09528458289181192\n",
      "Epoch: 113, Loss: 0.0941783213832726\n",
      "Epoch: 114, Loss: 0.09311314268658559\n",
      "Epoch: 115, Loss: 0.09208650623137753\n",
      "Epoch: 116, Loss: 0.09109604502251993\n",
      "Epoch: 117, Loss: 0.09013960557058454\n",
      "Epoch: 118, Loss: 0.08921514203151067\n",
      "Epoch: 119, Loss: 0.08832063634569447\n",
      "Epoch: 120, Loss: 0.08745441197728117\n",
      "Epoch: 121, Loss: 0.08661472991419335\n",
      "Epoch: 122, Loss: 0.08579997423415382\n",
      "Epoch: 123, Loss: 0.08500877690191071\n",
      "Epoch: 124, Loss: 0.0842397961144646\n",
      "Epoch: 125, Loss: 0.08349165910234053\n",
      "Epoch: 126, Loss: 0.08276321591498952\n",
      "Epoch: 127, Loss: 0.08205335346671443\n",
      "Epoch: 128, Loss: 0.08136102165250729\n",
      "Epoch: 129, Loss: 0.08068524615373462\n",
      "Epoch: 130, Loss: 0.08002511722346146\n",
      "Epoch: 131, Loss: 0.07937972837438186\n",
      "Epoch: 132, Loss: 0.07874832965899259\n",
      "Epoch: 133, Loss: 0.07813019802172978\n",
      "Epoch: 134, Loss: 0.07752457323173682\n",
      "Epoch: 135, Loss: 0.0769308094944184\n",
      "Epoch: 136, Loss: 0.07634835311910138\n",
      "Epoch: 137, Loss: 0.07577658429120977\n",
      "Epoch: 138, Loss: 0.07521493579649056\n",
      "Epoch: 139, Loss: 0.0746629947097972\n",
      "Epoch: 140, Loss: 0.0741202513454482\n",
      "Epoch: 141, Loss: 0.07358619320439175\n",
      "Epoch: 142, Loss: 0.0730605074010479\n",
      "Epoch: 143, Loss: 0.07254282055267443\n",
      "Epoch: 144, Loss: 0.0720326780671409\n",
      "Epoch: 145, Loss: 0.07152981358619097\n",
      "Epoch: 146, Loss: 0.07103389796490471\n",
      "Epoch: 147, Loss: 0.07054457998795745\n",
      "Epoch: 148, Loss: 0.07006164489818427\n",
      "Epoch: 149, Loss: 0.06958482333963427\n",
      "Epoch: 150, Loss: 0.06911383844756831\n",
      "Epoch: 151, Loss: 0.06864851523035516\n",
      "Epoch: 152, Loss: 0.06818862627551425\n",
      "Epoch: 153, Loss: 0.06773393568194781\n",
      "Epoch: 154, Loss: 0.06728426331149724\n",
      "Epoch: 155, Loss: 0.06683941808781431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████████████████▉                                                | 157/500 [00:00<00:00, 389.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 156, Loss: 0.06639926207329457\n",
      "Epoch: 157, Loss: 0.06596361930132844\n",
      "Epoch: 158, Loss: 0.06553235898900311\n",
      "Epoch: 159, Loss: 0.06510533916783363\n",
      "Epoch: 160, Loss: 0.06468242602568353\n",
      "Epoch: 161, Loss: 0.06426349724642932\n",
      "Epoch: 162, Loss: 0.06384841938173243\n",
      "Epoch: 163, Loss: 0.0634371039244191\n",
      "Epoch: 164, Loss: 0.06302943919339062\n",
      "Epoch: 165, Loss: 0.06262535509328397\n",
      "Epoch: 166, Loss: 0.06222472466470208\n",
      "Epoch: 167, Loss: 0.06182746648604128\n",
      "Epoch: 168, Loss: 0.06143352006256464\n",
      "Epoch: 169, Loss: 0.061042797501916844\n",
      "Epoch: 170, Loss: 0.060655188804958016\n",
      "Epoch: 171, Loss: 0.06027068420977836\n",
      "Epoch: 172, Loss: 0.05988920756681182\n",
      "Epoch: 173, Loss: 0.05951068915298189\n",
      "Epoch: 174, Loss: 0.059135058565516374\n",
      "Epoch: 175, Loss: 0.05876230796608676\n",
      "Epoch: 176, Loss: 0.0583923067467064\n",
      "Epoch: 177, Loss: 0.058025072372402065\n",
      "Epoch: 178, Loss: 0.05766052489677046\n",
      "Epoch: 179, Loss: 0.057298612187423714\n",
      "Epoch: 180, Loss: 0.056939285791941074\n",
      "Epoch: 181, Loss: 0.056582560036379924\n",
      "Epoch: 182, Loss: 0.05622835896338074\n",
      "Epoch: 183, Loss: 0.055876632178069485\n",
      "Epoch: 184, Loss: 0.05552736336486911\n",
      "Epoch: 185, Loss: 0.05518051348622066\n",
      "Epoch: 186, Loss: 0.054836040534989174\n",
      "Epoch: 187, Loss: 0.054493956117767084\n",
      "Epoch: 188, Loss: 0.05415419279718966\n",
      "Epoch: 189, Loss: 0.05381674912526554\n",
      "Epoch: 190, Loss: 0.05348155231702852\n",
      "Epoch: 191, Loss: 0.05314858595950985\n",
      "Epoch: 192, Loss: 0.052817840157482955\n",
      "Epoch: 193, Loss: 0.05248931327059836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████                                          | 200/500 [00:00<00:00, 401.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 194, Loss: 0.05216292442196391\n",
      "Epoch: 195, Loss: 0.05183871294639175\n",
      "Epoch: 196, Loss: 0.051516607636889\n",
      "Epoch: 197, Loss: 0.05119665532841585\n",
      "Epoch: 198, Loss: 0.05087873872495644\n",
      "Epoch: 199, Loss: 0.050562907651207446\n",
      "Epoch: 200, Loss: 0.050249100613048846\n",
      "Epoch: 201, Loss: 0.04993730483996236\n",
      "Epoch: 202, Loss: 0.04962757051089284\n",
      "Epoch: 203, Loss: 0.049319782552629476\n",
      "Epoch: 204, Loss: 0.04901399829274548\n",
      "Epoch: 205, Loss: 0.04871012124082578\n",
      "Epoch: 206, Loss: 0.04840820259929993\n",
      "Epoch: 207, Loss: 0.04810823143179732\n",
      "Epoch: 208, Loss: 0.0478101294793305\n",
      "Epoch: 209, Loss: 0.04751392482285155\n",
      "Epoch: 210, Loss: 0.04721960772258171\n",
      "Epoch: 211, Loss: 0.046927152924581605\n",
      "Epoch: 212, Loss: 0.04663656417324091\n",
      "Epoch: 213, Loss: 0.046347785832040245\n",
      "Epoch: 214, Loss: 0.04606081470107407\n",
      "Epoch: 215, Loss: 0.04577568399417942\n",
      "Epoch: 216, Loss: 0.04549234927435464\n",
      "Epoch: 217, Loss: 0.04521075421750235\n",
      "Epoch: 218, Loss: 0.04493092699097664\n",
      "Epoch: 219, Loss: 0.044652900901079796\n",
      "Epoch: 220, Loss: 0.0443765690276147\n",
      "Epoch: 221, Loss: 0.04410198662966044\n",
      "Epoch: 222, Loss: 0.04382910338730047\n",
      "Epoch: 223, Loss: 0.043557929748203605\n",
      "Epoch: 224, Loss: 0.0432884753045073\n",
      "Epoch: 225, Loss: 0.043020674571986696\n",
      "Epoch: 226, Loss: 0.04275455572011803\n",
      "Epoch: 227, Loss: 0.04249009443386361\n",
      "Epoch: 228, Loss: 0.04222726779577594\n",
      "Epoch: 229, Loss: 0.041966088107680356\n",
      "Epoch: 230, Loss: 0.04170653177425265\n",
      "Epoch: 231, Loss: 0.04144859504958731\n",
      "Epoch: 232, Loss: 0.0411922596176737\n",
      "Epoch: 233, Loss: 0.04093751730154812\n",
      "Epoch: 234, Loss: 0.040684349646350405\n",
      "Epoch: 235, Loss: 0.040432749204531625\n",
      "Epoch: 236, Loss: 0.04018274183727044\n",
      "Epoch: 237, Loss: 0.039934266829125896\n",
      "Epoch: 238, Loss: 0.039687319973988146\n",
      "Epoch: 239, Loss: 0.039441912519275014\n",
      "Epoch: 240, Loss: 0.0391980565849129\n",
      "Epoch: 241, Loss: 0.03895568312630834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|██████████████████████████████████                                    | 243/500 [00:00<00:00, 410.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 242, Loss: 0.038714810803867294\n",
      "Epoch: 243, Loss: 0.03847546526230872\n",
      "Epoch: 244, Loss: 0.038237578793390035\n",
      "Epoch: 245, Loss: 0.03800116634617249\n",
      "Epoch: 246, Loss: 0.037766227635681084\n",
      "Epoch: 247, Loss: 0.037532725772810714\n",
      "Epoch: 248, Loss: 0.03730069748417009\n",
      "Epoch: 249, Loss: 0.03707008665636143\n",
      "Epoch: 250, Loss: 0.036840919351258584\n",
      "Epoch: 251, Loss: 0.036613137741975756\n",
      "Epoch: 252, Loss: 0.03638682083631769\n",
      "Epoch: 253, Loss: 0.036161861182942324\n",
      "Epoch: 254, Loss: 0.035938291768009854\n",
      "Epoch: 255, Loss: 0.03571612402508132\n",
      "Epoch: 256, Loss: 0.03549532936024965\n",
      "Epoch: 257, Loss: 0.03527588841340427\n",
      "Epoch: 258, Loss: 0.03505779328952485\n",
      "Epoch: 259, Loss: 0.034841066775091654\n",
      "Epoch: 260, Loss: 0.03462568946512571\n",
      "Epoch: 261, Loss: 0.034411645186992246\n",
      "Epoch: 262, Loss: 0.03419892705763535\n",
      "Epoch: 263, Loss: 0.03398751525916547\n",
      "Epoch: 264, Loss: 0.03377740544359161\n",
      "Epoch: 265, Loss: 0.03356860074381984\n",
      "Epoch: 266, Loss: 0.03336105353506961\n",
      "Epoch: 267, Loss: 0.03315483053544691\n",
      "Epoch: 268, Loss: 0.032949856619476726\n",
      "Epoch: 269, Loss: 0.032746181483768545\n",
      "Epoch: 270, Loss: 0.03254375724948962\n",
      "Epoch: 271, Loss: 0.032342571241315454\n",
      "Epoch: 272, Loss: 0.03214264801257135\n",
      "Epoch: 273, Loss: 0.03194393199616267\n",
      "Epoch: 274, Loss: 0.031746474703444015\n",
      "Epoch: 275, Loss: 0.03155022460668988\n",
      "Epoch: 276, Loss: 0.0313551908111549\n",
      "Epoch: 277, Loss: 0.031161372621985112\n",
      "Epoch: 278, Loss: 0.03096874136341891\n",
      "Epoch: 279, Loss: 0.030777316736324185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|████████████████████████████████████████                              | 286/500 [00:00<00:00, 413.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 280, Loss: 0.03058703979877464\n",
      "Epoch: 281, Loss: 0.03039793629674629\n",
      "Epoch: 282, Loss: 0.03021004521724535\n",
      "Epoch: 283, Loss: 0.03002329258985507\n",
      "Epoch: 284, Loss: 0.029837703934996778\n",
      "Epoch: 285, Loss: 0.02965327176207211\n",
      "Epoch: 286, Loss: 0.029469933845878888\n",
      "Epoch: 287, Loss: 0.02928777487250045\n",
      "Epoch: 288, Loss: 0.029106720932759345\n",
      "Epoch: 289, Loss: 0.028926782006237772\n",
      "Epoch: 290, Loss: 0.02874796155083459\n",
      "Epoch: 291, Loss: 0.028570255167020758\n",
      "Epoch: 292, Loss: 0.02839366068171027\n",
      "Epoch: 293, Loss: 0.02821813998646879\n",
      "Epoch: 294, Loss: 0.02804371055147688\n",
      "Epoch: 295, Loss: 0.027870355692963738\n",
      "Epoch: 296, Loss: 0.0276980724617412\n",
      "Epoch: 297, Loss: 0.027526849455171032\n",
      "Epoch: 298, Loss: 0.027356695680282428\n",
      "Epoch: 299, Loss: 0.02718759204193096\n",
      "Epoch: 300, Loss: 0.02701954063559242\n",
      "Epoch: 301, Loss: 0.026852511370937766\n",
      "Epoch: 302, Loss: 0.02668650725900079\n",
      "Epoch: 303, Loss: 0.026521545218808267\n",
      "Epoch: 304, Loss: 0.026357592204779696\n",
      "Epoch: 305, Loss: 0.026194666674806893\n",
      "Epoch: 306, Loss: 0.026032735159484826\n",
      "Epoch: 307, Loss: 0.025871816422295524\n",
      "Epoch: 308, Loss: 0.025711887362073565\n",
      "Epoch: 309, Loss: 0.02555293472566215\n",
      "Epoch: 310, Loss: 0.02539497878084755\n",
      "Epoch: 311, Loss: 0.025237992300390033\n",
      "Epoch: 312, Loss: 0.02508196439339372\n",
      "Epoch: 313, Loss: 0.02492691767171588\n",
      "Epoch: 314, Loss: 0.02477283422619318\n",
      "Epoch: 315, Loss: 0.02461970245591753\n",
      "Epoch: 316, Loss: 0.024467515138288338\n",
      "Epoch: 317, Loss: 0.024316267383255763\n",
      "Epoch: 318, Loss: 0.024165935135291267\n",
      "Epoch: 319, Loss: 0.02401655079665943\n",
      "Epoch: 320, Loss: 0.023868093102161463\n",
      "Epoch: 321, Loss: 0.02372053900216997\n",
      "Epoch: 322, Loss: 0.023573895054141758\n",
      "Epoch: 323, Loss: 0.023428184179162297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|█████████████████████████████████████████████▉                        | 328/500 [00:00<00:00, 407.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 324, Loss: 0.023283369999262504\n",
      "Epoch: 325, Loss: 0.023139450849460747\n",
      "Epoch: 326, Loss: 0.022996411234392628\n",
      "Epoch: 327, Loss: 0.022854256530990824\n",
      "Epoch: 328, Loss: 0.022712975878069603\n",
      "Epoch: 329, Loss: 0.022572585453114396\n",
      "Epoch: 330, Loss: 0.022433051866149373\n",
      "Epoch: 331, Loss: 0.022294376969512086\n",
      "Epoch: 332, Loss: 0.022156562764090875\n",
      "Epoch: 333, Loss: 0.022019574391379138\n",
      "Epoch: 334, Loss: 0.02188346450505681\n",
      "Epoch: 335, Loss: 0.021748207191800855\n",
      "Epoch: 336, Loss: 0.021613765354535037\n",
      "Epoch: 337, Loss: 0.021480148693323525\n",
      "Epoch: 338, Loss: 0.021347354259584488\n",
      "Epoch: 339, Loss: 0.021215389121304423\n",
      "Epoch: 340, Loss: 0.021084250546361243\n",
      "Epoch: 341, Loss: 0.020953910105769562\n",
      "Epoch: 342, Loss: 0.02082437439154698\n",
      "Epoch: 343, Loss: 0.02069565645554879\n",
      "Epoch: 344, Loss: 0.020567704476585884\n",
      "Epoch: 345, Loss: 0.020440567629217792\n",
      "Epoch: 346, Loss: 0.020314204215537757\n",
      "Epoch: 347, Loss: 0.020188629286470434\n",
      "Epoch: 348, Loss: 0.020063818839237985\n",
      "Epoch: 349, Loss: 0.019939791305660037\n",
      "Epoch: 350, Loss: 0.0198165423401709\n",
      "Epoch: 351, Loss: 0.01969403202141014\n",
      "Epoch: 352, Loss: 0.01957229400371337\n",
      "Epoch: 353, Loss: 0.019451300337095745\n",
      "Epoch: 354, Loss: 0.019331053306207952\n",
      "Epoch: 355, Loss: 0.019211556584802263\n",
      "Epoch: 356, Loss: 0.01909278977351884\n",
      "Epoch: 357, Loss: 0.018974772616881335\n",
      "Epoch: 358, Loss: 0.018857463286015747\n",
      "Epoch: 359, Loss: 0.018740892093774164\n",
      "Epoch: 360, Loss: 0.01862502833561545\n",
      "Epoch: 361, Loss: 0.018509910190308194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████████████████████████████████████████████████▉                  | 371/500 [00:00<00:00, 411.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 362, Loss: 0.018395477554198198\n",
      "Epoch: 363, Loss: 0.018281777447555214\n",
      "Epoch: 364, Loss: 0.018168775322313497\n",
      "Epoch: 365, Loss: 0.01805645230342634\n",
      "Epoch: 366, Loss: 0.01794482096435483\n",
      "Epoch: 367, Loss: 0.017833891513267492\n",
      "Epoch: 368, Loss: 0.0177236419840483\n",
      "Epoch: 369, Loss: 0.017614094830908773\n",
      "Epoch: 370, Loss: 0.017505210630285244\n",
      "Epoch: 371, Loss: 0.017396996286455153\n",
      "Epoch: 372, Loss: 0.017289459302749794\n",
      "Epoch: 373, Loss: 0.017182581286154647\n",
      "Epoch: 374, Loss: 0.017076365530253195\n",
      "Epoch: 375, Loss: 0.016970797107812057\n",
      "Epoch: 376, Loss: 0.016865900724951643\n",
      "Epoch: 377, Loss: 0.01676162197964004\n",
      "Epoch: 378, Loss: 0.016658008951101994\n",
      "Epoch: 379, Loss: 0.016555034899890114\n",
      "Epoch: 380, Loss: 0.016452691522620928\n",
      "Epoch: 381, Loss: 0.016350983367980614\n",
      "Epoch: 382, Loss: 0.01624992388648631\n",
      "Epoch: 383, Loss: 0.016149463168706763\n",
      "Epoch: 384, Loss: 0.01604962984735418\n",
      "Epoch: 385, Loss: 0.015950425284548448\n",
      "Epoch: 386, Loss: 0.015851832321156206\n",
      "Epoch: 387, Loss: 0.015753838040230523\n",
      "Epoch: 388, Loss: 0.015656456212430687\n",
      "Epoch: 389, Loss: 0.015559649160119685\n",
      "Epoch: 390, Loss: 0.015463470480729788\n",
      "Epoch: 391, Loss: 0.015367881400379702\n",
      "Epoch: 392, Loss: 0.015272887716491823\n",
      "Epoch: 393, Loss: 0.015178460907312305\n",
      "Epoch: 394, Loss: 0.015084632754224003\n",
      "Epoch: 395, Loss: 0.014991377461228694\n",
      "Epoch: 396, Loss: 0.014898713008733466\n",
      "Epoch: 397, Loss: 0.014806613846606828\n",
      "Epoch: 398, Loss: 0.014715091913482562\n",
      "Epoch: 399, Loss: 0.014624125867461165\n",
      "Epoch: 400, Loss: 0.014533734501431658\n",
      "Epoch: 401, Loss: 0.014443907634510348\n",
      "Epoch: 402, Loss: 0.014354610967833045\n",
      "Epoch: 403, Loss: 0.014265869715321363\n",
      "Epoch: 404, Loss: 0.01417769229192345\n",
      "Epoch: 405, Loss: 0.014090040224497594\n",
      "Epoch: 406, Loss: 0.014002949941035089\n",
      "Epoch: 407, Loss: 0.013916379244316582\n",
      "Epoch: 408, Loss: 0.013830354474824466\n",
      "Epoch: 409, Loss: 0.013744866111058704\n",
      "Epoch: 410, Loss: 0.01365988275968751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|██████████████████████████████████████████████████████████▏           | 416/500 [00:01<00:00, 420.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 411, Loss: 0.013575445088160146\n",
      "Epoch: 412, Loss: 0.013491518728793986\n",
      "Epoch: 413, Loss: 0.013408111193105773\n",
      "Epoch: 414, Loss: 0.013325234510072429\n",
      "Epoch: 415, Loss: 0.013242857916338835\n",
      "Epoch: 416, Loss: 0.013160990000869788\n",
      "Epoch: 417, Loss: 0.013079631501871821\n",
      "Epoch: 418, Loss: 0.012998783296097827\n",
      "Epoch: 419, Loss: 0.012918429875753645\n",
      "Epoch: 420, Loss: 0.012838569702580571\n",
      "Epoch: 421, Loss: 0.012759212226228556\n",
      "Epoch: 422, Loss: 0.012680345361635167\n",
      "Epoch: 423, Loss: 0.012601958432848429\n",
      "Epoch: 424, Loss: 0.012524044857248859\n",
      "Epoch: 425, Loss: 0.012446626291421126\n",
      "Epoch: 426, Loss: 0.012369684972327377\n",
      "Epoch: 427, Loss: 0.012293224588574958\n",
      "Epoch: 428, Loss: 0.012217239908750344\n",
      "Epoch: 429, Loss: 0.012141706723317233\n",
      "Epoch: 430, Loss: 0.012066643703292357\n",
      "Epoch: 431, Loss: 0.011992058023376254\n",
      "Epoch: 432, Loss: 0.011917929204476726\n",
      "Epoch: 433, Loss: 0.011844234489520508\n",
      "Epoch: 434, Loss: 0.011771012429259523\n",
      "Epoch: 435, Loss: 0.011698245173344427\n",
      "Epoch: 436, Loss: 0.011625938316380294\n",
      "Epoch: 437, Loss: 0.011554054225295355\n",
      "Epoch: 438, Loss: 0.011482635193109067\n",
      "Epoch: 439, Loss: 0.011411643732268809\n",
      "Epoch: 440, Loss: 0.011341102419161567\n",
      "Epoch: 441, Loss: 0.011270980602906397\n",
      "Epoch: 442, Loss: 0.011201307146317655\n",
      "Epoch: 443, Loss: 0.011132060493158255\n",
      "Epoch: 444, Loss: 0.011063231505128593\n",
      "Epoch: 445, Loss: 0.010994835393224397\n",
      "Epoch: 446, Loss: 0.010926863601525838\n",
      "Epoch: 447, Loss: 0.010859319796509226\n",
      "Epoch: 448, Loss: 0.010792195596877718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|████████████████████████████████████████████████████████████████▎     | 459/500 [00:01<00:00, 420.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 449, Loss: 0.01072547456836522\n",
      "Epoch: 450, Loss: 0.010659190927981399\n",
      "Epoch: 451, Loss: 0.010593295351706425\n",
      "Epoch: 452, Loss: 0.01052780340736111\n",
      "Epoch: 453, Loss: 0.010462718696847636\n",
      "Epoch: 454, Loss: 0.010398048330292417\n",
      "Epoch: 455, Loss: 0.010333771427819253\n",
      "Epoch: 456, Loss: 0.010269880663448324\n",
      "Epoch: 457, Loss: 0.010206394364407364\n",
      "Epoch: 458, Loss: 0.010143305216843146\n",
      "Epoch: 459, Loss: 0.010080605442453816\n",
      "Epoch: 460, Loss: 0.010018276084641306\n",
      "Epoch: 461, Loss: 0.009956359648034171\n",
      "Epoch: 462, Loss: 0.009894811025333183\n",
      "Epoch: 463, Loss: 0.009833648997603936\n",
      "Epoch: 464, Loss: 0.009772846828733842\n",
      "Epoch: 465, Loss: 0.009712448103528004\n",
      "Epoch: 466, Loss: 0.009652399236074416\n",
      "Epoch: 467, Loss: 0.009592730933945859\n",
      "Epoch: 468, Loss: 0.009533436703956491\n",
      "Epoch: 469, Loss: 0.009474495508584369\n",
      "Epoch: 470, Loss: 0.009415926993824542\n",
      "Epoch: 471, Loss: 0.009357715948378123\n",
      "Epoch: 472, Loss: 0.009299873974669026\n",
      "Epoch: 473, Loss: 0.009242390416754157\n",
      "Epoch: 474, Loss: 0.009185251854736029\n",
      "Epoch: 475, Loss: 0.009128459772909991\n",
      "Epoch: 476, Loss: 0.009072033481364391\n",
      "Epoch: 477, Loss: 0.009015950104488487\n",
      "Epoch: 478, Loss: 0.008960217413308177\n",
      "Epoch: 479, Loss: 0.008904840614074297\n",
      "Epoch: 480, Loss: 0.008849787463683848\n",
      "Epoch: 481, Loss: 0.008795089247238744\n",
      "Epoch: 482, Loss: 0.008740715832876353\n",
      "Epoch: 483, Loss: 0.008686680708706263\n",
      "Epoch: 484, Loss: 0.008632984208816197\n",
      "Epoch: 485, Loss: 0.008579616515514013\n",
      "Epoch: 486, Loss: 0.008526566630280286\n",
      "Epoch: 487, Loss: 0.008473853790746944\n",
      "Epoch: 488, Loss: 0.008421470420216792\n",
      "Epoch: 489, Loss: 0.008369413417919228\n",
      "Epoch: 490, Loss: 0.00831767175047086\n",
      "Epoch: 491, Loss: 0.008266260490017885\n",
      "Epoch: 492, Loss: 0.008215152675802528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 404.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 493, Loss: 0.008164369260460566\n",
      "Epoch: 494, Loss: 0.008113897166670844\n",
      "Epoch: 495, Loss: 0.008063736332284558\n",
      "Epoch: 496, Loss: 0.008013883606812064\n",
      "Epoch: 497, Loss: 0.007964354461212983\n",
      "Epoch: 498, Loss: 0.007915117273417612\n",
      "Epoch: 499, Loss: 0.007866198451665696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 500\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    running_loss = 0\n",
    "    for idx, (x, y) in enumerate(trainloader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model_huber_class(x)\n",
    "        loss = HuberLoss(threshold=1.02)(y, output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch: {epoch}, Loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3113c15c",
   "metadata": {},
   "source": [
    "## Inference using Huber Loss Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79cf5261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18.6330], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sample = [10.0]\n",
    "\n",
    "# Set model to Eval mode\n",
    "model_huber_class.eval()\n",
    "output = model_huber_class(torch.tensor(sample))\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
